{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a) Variables & observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables, $p$\n",
    "*Predictor*<br> \n",
    "> *  conflict (high/low, qualitative)<br>\n",
    "*  volatility (high/low, qualitative)<br>\n",
    "\n",
    "*Response*<br>\n",
    ">*behavioral*\n",
    ">> *  accuracy (qualitative, 0/1)<br>\n",
    "*  reaction time (quantitative)<br>\n",
    "\n",
    "> *parameters from model fits to behavioral data*<br> \n",
    ">> *  decision boundary height [$a$] (quantitative)<br>\n",
    "*  drift rate [$v$] (quantitative)<br>\n",
    "*  starting point [$z$] (quantitative)<br>\n",
    "*  learning rate [$\\beta$] (quantitative)<br>\n",
    "\n",
    "> *learning signals from ideal observer*<br> \n",
    ">> *  change point probability [$\\Omega$] (quantitative)<br>\n",
    "*  belief in the reward difference between targets [$B$] (quantitative)\n",
    "\n",
    "### Number of observations, $n$\n",
    "6 participants with four 1000-trial sessions each. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# b) Data architecture "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All behavioral data and metadata will be stored within the lab Dropbox folder for the experiment.  Each data file is named according to subject, condition, and trial set ID. For example, if my subject number was 123, my condition number was 0, and the trial set ID was 0, then my data file would be named *123_cond0_trialset0.csv*. Additionally, for each subject, system- and experiment-related metadata, such as the last computer reboot time, the versions of key modules for the experiment, the total length of the experiment for that session, and  the length of the mid-experiment break, is recorded in a separate csv file with *runInfo* appended to the file name, as below.\n",
    "![image.png](data_arch.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>psychopy_version</th><th scope=col>python_version</th><th scope=col>pythonScipyVersion</th><th scope=col>pyglet_version</th><th scope=col>pygame_version</th><th scope=col>numpy_version</th><th scope=col>wx_version</th><th scope=col>window_refresh_time_avg_ms</th><th scope=col>begin_time</th><th scope=col>exp_dir</th><th scope=col>last_sys_reboot</th><th scope=col>system_platform</th><th scope=col>internet_access</th><th scope=col>total_exp_time</th><th scope=col>break_time</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>1.85.2                                                   </td><td>2.7.12                                                   </td><td>0.19.1                                                   </td><td>1.2.4                                                    </td><td>1.9.3                                                    </td><td>1.13.1                                                   </td><td>4.0.0b2 gtk3 (phoenix)                                   </td><td>33.33302                                                 </td><td>2018_02_02 17:49 (Year_Month_Day Hour:Min)               </td><td>/home/coaxlab/Dropbox/volatileValues/simple_rt_experiment</td><td>2018-02-02 16:32                                         </td><td>linux 4.4.0-112-generic                                  </td><td>True                                                     </td><td>24.63348                                                 </td><td>1.33224                                                  </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllllllllll}\n",
       " psychopy\\_version & python\\_version & pythonScipyVersion & pyglet\\_version & pygame\\_version & numpy\\_version & wx\\_version & window\\_refresh\\_time\\_avg\\_ms & begin\\_time & exp\\_dir & last\\_sys\\_reboot & system\\_platform & internet\\_access & total\\_exp\\_time & break\\_time\\\\\n",
       "\\hline\n",
       "\t 1.85.2                                                        & 2.7.12                                                        & 0.19.1                                                        & 1.2.4                                                         & 1.9.3                                                         & 1.13.1                                                        & 4.0.0b2 gtk3 (phoenix)                                        & 33.33302                                                      & 2018\\_02\\_02 17:49 (Year\\_Month\\_Day Hour:Min)            & /home/coaxlab/Dropbox/volatileValues/simple\\_rt\\_experiment & 2018-02-02 16:32                                              & linux 4.4.0-112-generic                                       & True                                                          & 24.63348                                                      & 1.33224                                                      \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "psychopy_version | python_version | pythonScipyVersion | pyglet_version | pygame_version | numpy_version | wx_version | window_refresh_time_avg_ms | begin_time | exp_dir | last_sys_reboot | system_platform | internet_access | total_exp_time | break_time | \n",
       "|---|\n",
       "| 1.85.2                                                    | 2.7.12                                                    | 0.19.1                                                    | 1.2.4                                                     | 1.9.3                                                     | 1.13.1                                                    | 4.0.0b2 gtk3 (phoenix)                                    | 33.33302                                                  | 2018_02_02 17:49 (Year_Month_Day Hour:Min)                | /home/coaxlab/Dropbox/volatileValues/simple_rt_experiment | 2018-02-02 16:32                                          | linux 4.4.0-112-generic                                   | True                                                      | 24.63348                                                  | 1.33224                                                   | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  psychopy_version python_version pythonScipyVersion pyglet_version\n",
       "1 1.85.2           2.7.12         0.19.1             1.2.4         \n",
       "  pygame_version numpy_version wx_version            \n",
       "1 1.9.3          1.13.1        4.0.0b2 gtk3 (phoenix)\n",
       "  window_refresh_time_avg_ms begin_time                                \n",
       "1 33.33302                   2018_02_02 17:49 (Year_Month_Day Hour:Min)\n",
       "  exp_dir                                                   last_sys_reboot \n",
       "1 /home/coaxlab/Dropbox/volatileValues/simple_rt_experiment 2018-02-02 16:32\n",
       "  system_platform         internet_access total_exp_time break_time\n",
       "1 linux 4.4.0-112-generic True            24.63348       1.33224   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "example_metadata <- read.csv(\"test_cond0_trialset0_runInfo.csv\")\n",
    "head(example_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within the behavioral data file, key variables are stored within columns:\n",
    "> * the left/right **choice** is coded as 0 or 1\n",
    "> * the **accuracy** is coded as 0 (incorrect) or 1 (correct)\n",
    "> * the choice corresponding to the highest point value is stored as the **solution**\n",
    "> * the number of points earned on each trial is stored as **reward**\n",
    "> * the reward accumulated across the experiment so far is stored as **cumulative_reward**\n",
    "> * the reaction time for each trial is stored as **rt**\n",
    "> * the trial time, including feedback time, is stored as **total_trial_time** \n",
    "> * the intertrial interval is stored as **iti**\n",
    "> * the change point indicator (0/1) is stored with slow trial (-1) and fast trial (-2) indicators as **cp_with_slow_fast**\n",
    "> * and the ASCII value for the color of the high-value cue is stored as **high_val_cue**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>choice</th><th scope=col>accuracy</th><th scope=col>solution</th><th scope=col>reward</th><th scope=col>cumulative_reward</th><th scope=col>rt</th><th scope=col>total_trial_time</th><th scope=col>iti</th><th scope=col>cp_with_slow_fast</th><th scope=col>high_val_cue</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>0        </td><td>0        </td><td>1        </td><td> 0       </td><td>  0      </td><td>1.0571220</td><td>2.711002 </td><td>0.6296882</td><td>-1       </td><td>112      </td></tr>\n",
       "\t<tr><td>0        </td><td>0        </td><td>1        </td><td>46       </td><td> 46      </td><td>0.2342849</td><td>1.896353 </td><td>0.6759479</td><td> 0       </td><td>112      </td></tr>\n",
       "\t<tr><td>0        </td><td>1        </td><td>0        </td><td>55       </td><td>101      </td><td>0.4263060</td><td>2.029746 </td><td>0.6224250</td><td> 0       </td><td>112      </td></tr>\n",
       "\t<tr><td>1        </td><td>0        </td><td>0        </td><td>38       </td><td>139      </td><td>0.3260748</td><td>1.660718 </td><td>0.3501943</td><td> 0       </td><td>112      </td></tr>\n",
       "\t<tr><td>0        </td><td>1        </td><td>0        </td><td>55       </td><td>194      </td><td>0.3734028</td><td>1.941348 </td><td>0.5746767</td><td> 0       </td><td>112      </td></tr>\n",
       "\t<tr><td>0        </td><td>0        </td><td>1        </td><td>41       </td><td>235      </td><td>0.3061411</td><td>1.755645 </td><td>0.4637496</td><td> 0       </td><td>112      </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllllll}\n",
       " choice & accuracy & solution & reward & cumulative\\_reward & rt & total\\_trial\\_time & iti & cp\\_with\\_slow\\_fast & high\\_val\\_cue\\\\\n",
       "\\hline\n",
       "\t 0         & 0         & 1         &  0        &   0       & 1.0571220 & 2.711002  & 0.6296882 & -1        & 112      \\\\\n",
       "\t 0         & 0         & 1         & 46        &  46       & 0.2342849 & 1.896353  & 0.6759479 &  0        & 112      \\\\\n",
       "\t 0         & 1         & 0         & 55        & 101       & 0.4263060 & 2.029746  & 0.6224250 &  0        & 112      \\\\\n",
       "\t 1         & 0         & 0         & 38        & 139       & 0.3260748 & 1.660718  & 0.3501943 &  0        & 112      \\\\\n",
       "\t 0         & 1         & 0         & 55        & 194       & 0.3734028 & 1.941348  & 0.5746767 &  0        & 112      \\\\\n",
       "\t 0         & 0         & 1         & 41        & 235       & 0.3061411 & 1.755645  & 0.4637496 &  0        & 112      \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "choice | accuracy | solution | reward | cumulative_reward | rt | total_trial_time | iti | cp_with_slow_fast | high_val_cue | \n",
       "|---|---|---|---|---|---|\n",
       "| 0         | 0         | 1         |  0        |   0       | 1.0571220 | 2.711002  | 0.6296882 | -1        | 112       | \n",
       "| 0         | 0         | 1         | 46        |  46       | 0.2342849 | 1.896353  | 0.6759479 |  0        | 112       | \n",
       "| 0         | 1         | 0         | 55        | 101       | 0.4263060 | 2.029746  | 0.6224250 |  0        | 112       | \n",
       "| 1         | 0         | 0         | 38        | 139       | 0.3260748 | 1.660718  | 0.3501943 |  0        | 112       | \n",
       "| 0         | 1         | 0         | 55        | 194       | 0.3734028 | 1.941348  | 0.5746767 |  0        | 112       | \n",
       "| 0         | 0         | 1         | 41        | 235       | 0.3061411 | 1.755645  | 0.4637496 |  0        | 112       | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  choice accuracy solution reward cumulative_reward rt        total_trial_time\n",
       "1 0      0        1         0       0               1.0571220 2.711002        \n",
       "2 0      0        1        46      46               0.2342849 1.896353        \n",
       "3 0      1        0        55     101               0.4263060 2.029746        \n",
       "4 1      0        0        38     139               0.3260748 1.660718        \n",
       "5 0      1        0        55     194               0.3734028 1.941348        \n",
       "6 0      0        1        41     235               0.3061411 1.755645        \n",
       "  iti       cp_with_slow_fast high_val_cue\n",
       "1 0.6296882 -1                112         \n",
       "2 0.6759479  0                112         \n",
       "3 0.6224250  0                112         \n",
       "4 0.3501943  0                112         \n",
       "5 0.5746767  0                112         \n",
       "6 0.4637496  0                112         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "example_data <- read.csv(\"test_cond0_trialset0.csv\")\n",
    "head(example_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because data collection is still ongoing, I don't have a sample data structure to show for the parameters from model fits. However, the learning signals resulting from ideal observer simulations (change point probability, $\\Omega$ and belief in the reward difference between targets, $B$) are currently stored within Python objects named for each candidate model of learning. Each object is named for the learning rate (for ex., 'mod' for moderate), the condition (for ex., 'hv_hc' for high volatility and high conflict), the learning signal (for ex., 'B' for the belief in the difference between targets, $B$), and the target of learning (for ex., 'sp' for starting point, $Z$):   \n",
    "![image.png](python_objects.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# c) Anticipated anomalies & data cleansing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ## Syntactic \n",
    "> > **Lexical**: Because the behavioral data is written to lists which are concatenated, there would be a concatenation error if they were of different sizes that would prevent saving the data, so I don't expect there to be any discrepancies between the intended and actual data structure format. However, is possible that the values for two variables could be switched without affecting the size of the list, so I will check for this type of error.\n",
    "<br>\n",
    "> > **Domain format errors and irregularities**: Because all of the data is written at once, I don't expect there to be formatting inconsistencies, but I will check for this type of error.\n",
    "<br>\n",
    "* ## Semantic \n",
    "> > **Integrity constraint violations**: Will check that reaction times are within the minimum (.1 s) and maximum (1 s) set within the experiment. Because the trial should end with a timing message if either the max. or min. reaction time is recorded, if reaction times associated with a non-repeated trial are greater than the maximum or less than the minimum , then a) the reaction time was recorded incorrectly or b) the experiment did not operate as intended. I will check that accuracy, solution, and choice values are all either 0 or 1 and that the high value cue is always either one of the two ASCII values for the colors of the stimuli presented. \n",
    "<br>\n",
    "> > **Contradictions**: I will recalculate accuracy from the choice and the solution values to ensure that the accuracy variable does not represent a contradiction. Additionally, I will ensure that if the experimental constraints on reaction time are not met on a given trial,  the trial is flagged appropriately (-1 or -2 for fast for slow trials) and that the trial is repeated (same reward values on the t+1 as t). Additionally, I will check that total trial time is always greater than the recorded reaction time, that cumulative reward is always increasing, and that when the cp_with_fast_slow indicator is 1 (indicating a change point), then the ASCII value for the high value cue also changes. \n",
    "<br>\n",
    "> > **Duplicates**: While some trials should repeat given an out-of-bounds reaction time, I will check for repeated recordings of the same trial by finding whether any trial within a subject has repeated values for reaction time (which has a high degree of precision) and cumulative reward (which should always increase). \n",
    "<br>\n",
    "> > **Invalid tuples**: I will check that accuracy is moderately variable within a given subject. Given the probabilistic nature of the task, I would not expect a subject to have either perfect accuracy or for that subject to have all incorrect trials. \n",
    "<br>\n",
    "\n",
    "* ## Coverage \n",
    "> > **Missing values & missing tuples**: Missing values within a variable should not be a problem because the data would not save due to a concatenation error. Missing data vectors also should not be a problem because of the automated data collection, but I will check that the data from each subject matches the expected size (number of trials by number of variables). \n",
    "<br>\n",
    "\n",
    "\n",
    "## Overall approach\n",
    "Because it is feasible (timewise and computationally) to check all of my data, I will not select a subset for data auditing -- I'll audit all of it. I'll write detection/resolution scripts appropriate to the above anomalies, then re-run the detection scripts to ensure that all anomalies have been found and corrected. More detail/sample code for this will be included in the next edit of my data plan.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# d) Clean data table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My data table will be in the tidy data format, with columns for subject ID, condition, reaction time, accuracy, and choice. Each observation will form a single row and the header of the data table will refers to the names of the variables. Each column will refer to a single variable and variables will only be stored in columns (not rows). Because I only have one type of observational unit (the participant), I can store all of the data that I mentioned within a single data table. This approach is compliant with the tidy data format and avoids common problems resulting from messy data storage. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# e) Hypotheses to test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Mechanism*\n",
    "<br>\n",
    "Either the rate of evidence accumulation [drift rate, $v$] or the starting point for evidence accumulation [$z$] will vary with conflict, such that larger differences in value either increase the drift rate or bias the starting point toward the higher-value target, and smaller differences in value decrease the drift rate or decrease starting point bias (so that $z$ is closer to $a$/2).\n",
    "<br>\n",
    "$$v_{t+1} = \\hat\\beta*B_{t} + v_{t}$$\n",
    "$$z_{t+1} = \\hat\\beta*B_{t} + z_{0}$$\n",
    "<br>\n",
    "The decision threshold [$a$] will increase as volatility increases and decrease as volatility decreases. Increased volatility will increase learning rates [$\\beta$]. \n",
    "\n",
    "$$a_{t+1} = \\hat\\beta*\\Omega_{t} + a_{0}$$\n",
    "\n",
    "Decision threshold and drift rate adaptation will likely combine to drive behavior, with the threshold shift driven by change point probability and affecting both targets, or by belief in the reward difference changing the starting point, biasing the decision toward the high value target. The drift rate change will be driven by belief in the reward difference. \n",
    "\n",
    "*Behavior*\n",
    "<br>\n",
    "As a consequence of the above mechanisms, I predict that accuracy will decrease as volatility and conflict increase. Reaction times will increase more quickly under conditions of high volatility than high conflict, which will show a slow increase in reaction time as the learner disambiguates the value difference between targets. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# f) Data visualization approach"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because I'm interested in learning (i.e., change over time), I plan to use changepoint-locked time series plots of subject- and epoch-averaged reaction times (in seconds) and accuracies (as probability of correct selection) with 95% confidence intervals as shaded bars. I may use bootstrapped confidence intervals depending on whether the distribution of my data is normal. I plan to show the trial before the change point to 20 trials after the change point. The same approach can be used for my model parameters ($a$, $v$, $z$). Below is an example of this plotting style using simulated data:\n",
    "![image.png](hvhc_acc_tc.png)\n",
    "\n",
    "I also plan to show the full distributions of my parameters, reaction time, and accuracy data as function of condition, perhaps using a separate ridgeline plot for each variable (though I need to look into this further). I think that this type of plot could be used to illustrate distriubution-level differences over the full set of conditions.  While unrelated to my data, here's a sample of the ridgeline plot style from rstudio.com:\n",
    "![image.png](https://rviews.rstudio.com/post/2017-10-19-Top-40_files/ggridges.png)\n",
    "\n",
    "Additionally, I am considering using a deviation plot to show how well ideal observer estimates portray my observed data, but I need to think about this more. I could simply plot the ideal observer values against observations, with the identity line representing a perfect correspondence between the two, but I think that there is likely a more creative/interesting visualization approach that I could use."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
