{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Learning to decide in a changing world**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Background**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing successfully in a changing environment requires making fast, accurate decisions and updating those decisions given the feedback that you receive. For example, imagine that you’re a coffee lover. You’re in luck! Your favorite coffee shop has two single-origin beans that you enjoy — an Ethiopian and a Jamaican light roast. You might be conflicted about your choice and take longer than usual to decide, and because both of these beans are nearly equally valuable to you, you may not choose the beans that you would have liked best. Imagine that it’s the next week and you make your usual morning visit. Because of unseasonably dry growing conditions in Jamaica, the beans that you previously liked almost as much as the Ethiopian beans taste odd, so on your next visit, you vastly prefer the alternative. How does your estimate of whether the taste of your favorite bean has changed (volatility) interact with the value you place on each type of bean (decision-conflict)? Broadly, how do estimates of volatility and decision-conflict affect decision-making and learning?\n",
    "<br>\n",
    "To more fully understand decision making and learning in an environment with multiple sources of uncertainty, I explore how value conflict between competing actions (the degree to which the value associated with each action is similar) and the volatility of feedback (the change point frequency of mean value-action associations) influence adaptive decision making. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Variables**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables, $p$\n",
    "*Predictor*<br> \n",
    "> *  conflict (high/low, qualitative)<br>\n",
    "*  volatility (high/low, qualitative)<br>\n",
    "\n",
    "*Response*<br>\n",
    "> *  accuracy (qualitative, 0/1)<br>\n",
    "*  reaction time (quantitative)<br>\n",
    "\n",
    "### Number of observations, $n$\n",
    "5 participants with four 1000-trial sessions each.\n",
    "<br><br>\n",
    " ### Method of data collection \n",
    " In the task, we operationally define **conflict** as the mean reward difference between actions and **volatility** as the rate of change in that mean reward difference. We manipulated factors of volatility and conflict using a 2x2 within-subjects design to form four conditions, with each participant performing 1000 trials per condition and one condition per day until all conditions were complete.    \n",
    "\n",
    "Reaction time and choice accuracy data were collected using a two-alternative forced-choice task written in PsychoPy. On each trial, participants were asked to choose the highest-reward target within 1 s. Then they were shown the reward earned on each trial based on their decision. To prevent prepotent selections, the position of the rewarding target was  randomized across trials, with the target identity as the rewarding feature (rather than target position). The instruction screen and the structure of a sample trial are below: \n",
    "<tr><td><img src='instructions.png' style='width: 700px;'></td><td><img src='task.png' style='width: 700px;'></td></tr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Hypotheses**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A mixed effects logistic regression will evaluate my hypotheses regarding accuracy. Here $c$ is an indicator variable (high conflict = 1 and low conflict = 0), $v$ is an indicator variable (high volatility = 1 and low volatility = 0) and $id$ represents the subject ID: \n",
    "\n",
    "$$\\hat{a} = \\hat{\\beta_0} + \\hat{\\beta_c}c + \\hat{\\beta_v}v + \\hat{\\beta_{cv}}cv + (1|id)$$\n",
    "\n",
    "High volatility conditions will increase the log odds of making the correct choice relative to low volatility conditions, so $\\hat{\\beta_v}$ would be positive and significantly different from zero. High conflict conditions will decrease the log odds of making the correct choice relative to low conflict conditions, so $\\hat{\\beta_c}$ would be negative and significantly different from zero. Interaction effects may also exist such that conflict modifies the effect of volatility on the log odds of accuracy. \n",
    "\n",
    "\n",
    "<br>\n",
    "A mixed effects linear regression will evaluate my hypotheses regarding reaction times: \n",
    "\n",
    "$$\\hat{r} = \\hat{\\beta_0} + \\hat{\\beta_c}c + \\hat{\\beta_v}v + \\hat{\\beta_{cv}}cv + (1|id)$$\n",
    "\n",
    "High volatility conditions will increase reaction time more quickly relative to low volatility conditions, so $\\hat{\\beta_v}$ would be positive and significantly different from zero. High conflict conditions will delay and subdue the expression of reaction time increases relative to low conflict conditions, so $\\hat{\\beta_c}$ would be negative and significantly different from zero. Interaction effects may also exist such that conflict modifies the effect of volatility on reaction time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data organization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Architecture "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All behavioral data and metadata are stored within a Dropbox folder.  Each data file is named according to subject, condition, and trial set ID. For example, if my subject number was 123, my condition number was 0, and the trial set ID was 0, then my data file would be named *123_cond0_trialset0.csv*. Additionally, for each subject, system- and experiment-related metadata, such as the last computer reboot time, the versions of key modules for the experiment, the total length of the experiment for that session, and  the length of the mid-experiment break, is recorded in a separate csv file with *runInfo* appended to the file name, as below.\n",
    "![image.png](data_arch.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>psychopy_version</th><th scope=col>python_version</th><th scope=col>pythonScipyVersion</th><th scope=col>pyglet_version</th><th scope=col>pygame_version</th><th scope=col>numpy_version</th><th scope=col>wx_version</th><th scope=col>window_refresh_time_avg_ms</th><th scope=col>begin_time</th><th scope=col>exp_dir</th><th scope=col>last_sys_reboot</th><th scope=col>system_platform</th><th scope=col>internet_access</th><th scope=col>total_exp_time</th><th scope=col>break_time</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>1.85.2                                                   </td><td>2.7.12                                                   </td><td>0.19.1                                                   </td><td>1.2.4                                                    </td><td>1.9.3                                                    </td><td>1.13.1                                                   </td><td>4.0.0b2 gtk3 (phoenix)                                   </td><td>33.33302                                                 </td><td>2018_02_02 17:49 (Year_Month_Day Hour:Min)               </td><td>/home/coaxlab/Dropbox/volatileValues/simple_rt_experiment</td><td>2018-02-02 16:32                                         </td><td>linux 4.4.0-112-generic                                  </td><td>True                                                     </td><td>24.63348                                                 </td><td>1.33224                                                  </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllllllllll}\n",
       " psychopy\\_version & python\\_version & pythonScipyVersion & pyglet\\_version & pygame\\_version & numpy\\_version & wx\\_version & window\\_refresh\\_time\\_avg\\_ms & begin\\_time & exp\\_dir & last\\_sys\\_reboot & system\\_platform & internet\\_access & total\\_exp\\_time & break\\_time\\\\\n",
       "\\hline\n",
       "\t 1.85.2                                                        & 2.7.12                                                        & 0.19.1                                                        & 1.2.4                                                         & 1.9.3                                                         & 1.13.1                                                        & 4.0.0b2 gtk3 (phoenix)                                        & 33.33302                                                      & 2018\\_02\\_02 17:49 (Year\\_Month\\_Day Hour:Min)            & /home/coaxlab/Dropbox/volatileValues/simple\\_rt\\_experiment & 2018-02-02 16:32                                              & linux 4.4.0-112-generic                                       & True                                                          & 24.63348                                                      & 1.33224                                                      \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "psychopy_version | python_version | pythonScipyVersion | pyglet_version | pygame_version | numpy_version | wx_version | window_refresh_time_avg_ms | begin_time | exp_dir | last_sys_reboot | system_platform | internet_access | total_exp_time | break_time | \n",
       "|---|\n",
       "| 1.85.2                                                    | 2.7.12                                                    | 0.19.1                                                    | 1.2.4                                                     | 1.9.3                                                     | 1.13.1                                                    | 4.0.0b2 gtk3 (phoenix)                                    | 33.33302                                                  | 2018_02_02 17:49 (Year_Month_Day Hour:Min)                | /home/coaxlab/Dropbox/volatileValues/simple_rt_experiment | 2018-02-02 16:32                                          | linux 4.4.0-112-generic                                   | True                                                      | 24.63348                                                  | 1.33224                                                   | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  psychopy_version python_version pythonScipyVersion pyglet_version\n",
       "1 1.85.2           2.7.12         0.19.1             1.2.4         \n",
       "  pygame_version numpy_version wx_version            \n",
       "1 1.9.3          1.13.1        4.0.0b2 gtk3 (phoenix)\n",
       "  window_refresh_time_avg_ms begin_time                                \n",
       "1 33.33302                   2018_02_02 17:49 (Year_Month_Day Hour:Min)\n",
       "  exp_dir                                                   last_sys_reboot \n",
       "1 /home/coaxlab/Dropbox/volatileValues/simple_rt_experiment 2018-02-02 16:32\n",
       "  system_platform         internet_access total_exp_time break_time\n",
       "1 linux 4.4.0-112-generic True            24.63348       1.33224   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "example_metadata <- read.csv(\"test_cond0_trialset0_runInfo.csv\")\n",
    "head(example_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within the behavioral data file, key variables are stored within columns:\n",
    "> * the left/right **choice** is coded as 0 or 1\n",
    "> * the **accuracy** is coded as 0 (incorrect) or 1 (correct)\n",
    "> * the choice corresponding to the highest point value is stored as the **solution**\n",
    "> * the number of points earned on each trial is stored as **reward**\n",
    "> * the reward accumulated across the experiment so far is stored as **cumulative_reward**\n",
    "> * the reaction time for each trial is stored as **rt**\n",
    "> * the trial time, including feedback time, is stored as **total_trial_time** \n",
    "> * the intertrial interval is stored as **iti**\n",
    "> * the change point indicator (0/1) is stored with slow trial (-1) and fast trial (-2) indicators as **cp_with_slow_fast**\n",
    "> * and the ASCII value for the color of the high-value cue is stored as **high_val_cue**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>choice</th><th scope=col>accuracy</th><th scope=col>solution</th><th scope=col>reward</th><th scope=col>cumulative_reward</th><th scope=col>rt</th><th scope=col>total_trial_time</th><th scope=col>iti</th><th scope=col>cp_with_slow_fast</th><th scope=col>high_val_cue</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>0        </td><td>0        </td><td>1        </td><td> 0       </td><td>  0      </td><td>1.0571220</td><td>2.711002 </td><td>0.6296882</td><td>-1       </td><td>112      </td></tr>\n",
       "\t<tr><td>0        </td><td>0        </td><td>1        </td><td>46       </td><td> 46      </td><td>0.2342849</td><td>1.896353 </td><td>0.6759479</td><td> 0       </td><td>112      </td></tr>\n",
       "\t<tr><td>0        </td><td>1        </td><td>0        </td><td>55       </td><td>101      </td><td>0.4263060</td><td>2.029746 </td><td>0.6224250</td><td> 0       </td><td>112      </td></tr>\n",
       "\t<tr><td>1        </td><td>0        </td><td>0        </td><td>38       </td><td>139      </td><td>0.3260748</td><td>1.660718 </td><td>0.3501943</td><td> 0       </td><td>112      </td></tr>\n",
       "\t<tr><td>0        </td><td>1        </td><td>0        </td><td>55       </td><td>194      </td><td>0.3734028</td><td>1.941348 </td><td>0.5746767</td><td> 0       </td><td>112      </td></tr>\n",
       "\t<tr><td>0        </td><td>0        </td><td>1        </td><td>41       </td><td>235      </td><td>0.3061411</td><td>1.755645 </td><td>0.4637496</td><td> 0       </td><td>112      </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllllll}\n",
       " choice & accuracy & solution & reward & cumulative\\_reward & rt & total\\_trial\\_time & iti & cp\\_with\\_slow\\_fast & high\\_val\\_cue\\\\\n",
       "\\hline\n",
       "\t 0         & 0         & 1         &  0        &   0       & 1.0571220 & 2.711002  & 0.6296882 & -1        & 112      \\\\\n",
       "\t 0         & 0         & 1         & 46        &  46       & 0.2342849 & 1.896353  & 0.6759479 &  0        & 112      \\\\\n",
       "\t 0         & 1         & 0         & 55        & 101       & 0.4263060 & 2.029746  & 0.6224250 &  0        & 112      \\\\\n",
       "\t 1         & 0         & 0         & 38        & 139       & 0.3260748 & 1.660718  & 0.3501943 &  0        & 112      \\\\\n",
       "\t 0         & 1         & 0         & 55        & 194       & 0.3734028 & 1.941348  & 0.5746767 &  0        & 112      \\\\\n",
       "\t 0         & 0         & 1         & 41        & 235       & 0.3061411 & 1.755645  & 0.4637496 &  0        & 112      \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "choice | accuracy | solution | reward | cumulative_reward | rt | total_trial_time | iti | cp_with_slow_fast | high_val_cue | \n",
       "|---|---|---|---|---|---|\n",
       "| 0         | 0         | 1         |  0        |   0       | 1.0571220 | 2.711002  | 0.6296882 | -1        | 112       | \n",
       "| 0         | 0         | 1         | 46        |  46       | 0.2342849 | 1.896353  | 0.6759479 |  0        | 112       | \n",
       "| 0         | 1         | 0         | 55        | 101       | 0.4263060 | 2.029746  | 0.6224250 |  0        | 112       | \n",
       "| 1         | 0         | 0         | 38        | 139       | 0.3260748 | 1.660718  | 0.3501943 |  0        | 112       | \n",
       "| 0         | 1         | 0         | 55        | 194       | 0.3734028 | 1.941348  | 0.5746767 |  0        | 112       | \n",
       "| 0         | 0         | 1         | 41        | 235       | 0.3061411 | 1.755645  | 0.4637496 |  0        | 112       | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  choice accuracy solution reward cumulative_reward rt        total_trial_time\n",
       "1 0      0        1         0       0               1.0571220 2.711002        \n",
       "2 0      0        1        46      46               0.2342849 1.896353        \n",
       "3 0      1        0        55     101               0.4263060 2.029746        \n",
       "4 1      0        0        38     139               0.3260748 1.660718        \n",
       "5 0      1        0        55     194               0.3734028 1.941348        \n",
       "6 0      0        1        41     235               0.3061411 1.755645        \n",
       "  iti       cp_with_slow_fast high_val_cue\n",
       "1 0.6296882 -1                112         \n",
       "2 0.6759479  0                112         \n",
       "3 0.6224250  0                112         \n",
       "4 0.3501943  0                112         \n",
       "5 0.5746767  0                112         \n",
       "6 0.4637496  0                112         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "example_data <- read.csv(\"test_cond0_trialset0.csv\")\n",
    "head(example_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Table Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My data table is in the tidy data format, with columns for subject ID, condition, reaction time, and accuracy. Each observation is a single row and the header of the data table refers to the names of the variables. Because I only have one type of observational unit (the participant), I store all of the data within a single data table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df <- read.csv(\"cleaned_valC_data.csv\")\n",
    "colnames(clean_df)[1] <- 'trial'\n",
    "sparse_df <- clean_df[,c(\"ID\",\"condition\",\"rt\",\"accuracy\")]\n",
    "raw_df <- read.csv(\"raw_valC_data.csv\")\n",
    "colnames(raw_df)[1] <- 'trial'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>ID</th><th scope=col>condition</th><th scope=col>rt</th><th scope=col>accuracy</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>758      </td><td>lvhc     </td><td>0.2779109</td><td>1        </td></tr>\n",
       "\t<tr><td>758      </td><td>lvhc     </td><td>0.4092290</td><td>1        </td></tr>\n",
       "\t<tr><td>758      </td><td>lvhc     </td><td>0.3257351</td><td>1        </td></tr>\n",
       "\t<tr><td>758      </td><td>lvhc     </td><td>0.3317959</td><td>1        </td></tr>\n",
       "\t<tr><td>758      </td><td>lvhc     </td><td>0.2648199</td><td>1        </td></tr>\n",
       "\t<tr><td>758      </td><td>lvhc     </td><td>0.3168850</td><td>1        </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       " ID & condition & rt & accuracy\\\\\n",
       "\\hline\n",
       "\t 758       & lvhc      & 0.2779109 & 1        \\\\\n",
       "\t 758       & lvhc      & 0.4092290 & 1        \\\\\n",
       "\t 758       & lvhc      & 0.3257351 & 1        \\\\\n",
       "\t 758       & lvhc      & 0.3317959 & 1        \\\\\n",
       "\t 758       & lvhc      & 0.2648199 & 1        \\\\\n",
       "\t 758       & lvhc      & 0.3168850 & 1        \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "ID | condition | rt | accuracy | \n",
       "|---|---|---|---|---|---|\n",
       "| 758       | lvhc      | 0.2779109 | 1         | \n",
       "| 758       | lvhc      | 0.4092290 | 1         | \n",
       "| 758       | lvhc      | 0.3257351 | 1         | \n",
       "| 758       | lvhc      | 0.3317959 | 1         | \n",
       "| 758       | lvhc      | 0.2648199 | 1         | \n",
       "| 758       | lvhc      | 0.3168850 | 1         | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  ID  condition rt        accuracy\n",
       "1 758 lvhc      0.2779109 1       \n",
       "2 758 lvhc      0.4092290 1       \n",
       "3 758 lvhc      0.3257351 1       \n",
       "4 758 lvhc      0.3317959 1       \n",
       "5 758 lvhc      0.2648199 1       \n",
       "6 758 lvhc      0.3168850 1       "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>trial</th><th scope=col>reward</th><th scope=col>total_trial_time</th><th scope=col>accuracy</th><th scope=col>cp_with_slow_fast</th><th scope=col>cumulative_reward</th><th scope=col>high_val_cue</th><th scope=col>iti</th><th scope=col>rt</th><th scope=col>solution</th><th scope=col>choice</th><th scope=col>ID</th><th scope=col>condition</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>0        </td><td> 0       </td><td>2.564753 </td><td>1        </td><td>-1       </td><td>  0      </td><td>112      </td><td>0.2665031</td><td>1.2654541</td><td>1        </td><td>1        </td><td>758      </td><td>lvhc     </td></tr>\n",
       "\t<tr><td>1        </td><td>62       </td><td>1.571029 </td><td>1        </td><td> 0       </td><td> 62      </td><td>112      </td><td>0.2876267</td><td>0.2779109</td><td>1        </td><td>1        </td><td>758      </td><td>lvhc     </td></tr>\n",
       "\t<tr><td>2        </td><td>55       </td><td>2.015825 </td><td>1        </td><td> 0       </td><td>117      </td><td>112      </td><td>0.6198438</td><td>0.4092290</td><td>1        </td><td>1        </td><td>758      </td><td>lvhc     </td></tr>\n",
       "\t<tr><td>3        </td><td>60       </td><td>1.798977 </td><td>1        </td><td> 0       </td><td>177      </td><td>112      </td><td>0.4857087</td><td>0.3257351</td><td>1        </td><td>1        </td><td>758      </td><td>lvhc     </td></tr>\n",
       "\t<tr><td>4        </td><td>62       </td><td>1.911995 </td><td>1        </td><td> 0       </td><td>239      </td><td>112      </td><td>0.5810355</td><td>0.3317959</td><td>0        </td><td>0        </td><td>758      </td><td>lvhc     </td></tr>\n",
       "\t<tr><td>5        </td><td>59       </td><td>1.699535 </td><td>1        </td><td> 0       </td><td>298      </td><td>112      </td><td>0.4474356</td><td>0.2648199</td><td>1        </td><td>1        </td><td>758      </td><td>lvhc     </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllllllll}\n",
       " trial & reward & total\\_trial\\_time & accuracy & cp\\_with\\_slow\\_fast & cumulative\\_reward & high\\_val\\_cue & iti & rt & solution & choice & ID & condition\\\\\n",
       "\\hline\n",
       "\t 0         &  0        & 2.564753  & 1         & -1        &   0       & 112       & 0.2665031 & 1.2654541 & 1         & 1         & 758       & lvhc     \\\\\n",
       "\t 1         & 62        & 1.571029  & 1         &  0        &  62       & 112       & 0.2876267 & 0.2779109 & 1         & 1         & 758       & lvhc     \\\\\n",
       "\t 2         & 55        & 2.015825  & 1         &  0        & 117       & 112       & 0.6198438 & 0.4092290 & 1         & 1         & 758       & lvhc     \\\\\n",
       "\t 3         & 60        & 1.798977  & 1         &  0        & 177       & 112       & 0.4857087 & 0.3257351 & 1         & 1         & 758       & lvhc     \\\\\n",
       "\t 4         & 62        & 1.911995  & 1         &  0        & 239       & 112       & 0.5810355 & 0.3317959 & 0         & 0         & 758       & lvhc     \\\\\n",
       "\t 5         & 59        & 1.699535  & 1         &  0        & 298       & 112       & 0.4474356 & 0.2648199 & 1         & 1         & 758       & lvhc     \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "trial | reward | total_trial_time | accuracy | cp_with_slow_fast | cumulative_reward | high_val_cue | iti | rt | solution | choice | ID | condition | \n",
       "|---|---|---|---|---|---|\n",
       "| 0         |  0        | 2.564753  | 1         | -1        |   0       | 112       | 0.2665031 | 1.2654541 | 1         | 1         | 758       | lvhc      | \n",
       "| 1         | 62        | 1.571029  | 1         |  0        |  62       | 112       | 0.2876267 | 0.2779109 | 1         | 1         | 758       | lvhc      | \n",
       "| 2         | 55        | 2.015825  | 1         |  0        | 117       | 112       | 0.6198438 | 0.4092290 | 1         | 1         | 758       | lvhc      | \n",
       "| 3         | 60        | 1.798977  | 1         |  0        | 177       | 112       | 0.4857087 | 0.3257351 | 1         | 1         | 758       | lvhc      | \n",
       "| 4         | 62        | 1.911995  | 1         |  0        | 239       | 112       | 0.5810355 | 0.3317959 | 0         | 0         | 758       | lvhc      | \n",
       "| 5         | 59        | 1.699535  | 1         |  0        | 298       | 112       | 0.4474356 | 0.2648199 | 1         | 1         | 758       | lvhc      | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  trial reward total_trial_time accuracy cp_with_slow_fast cumulative_reward\n",
       "1 0      0     2.564753         1        -1                  0              \n",
       "2 1     62     1.571029         1         0                 62              \n",
       "3 2     55     2.015825         1         0                117              \n",
       "4 3     60     1.798977         1         0                177              \n",
       "5 4     62     1.911995         1         0                239              \n",
       "6 5     59     1.699535         1         0                298              \n",
       "  high_val_cue iti       rt        solution choice ID  condition\n",
       "1 112          0.2665031 1.2654541 1        1      758 lvhc     \n",
       "2 112          0.2876267 0.2779109 1        1      758 lvhc     \n",
       "3 112          0.6198438 0.4092290 1        1      758 lvhc     \n",
       "4 112          0.4857087 0.3257351 1        1      758 lvhc     \n",
       "5 112          0.5810355 0.3317959 0        0      758 lvhc     \n",
       "6 112          0.4474356 0.2648199 1        1      758 lvhc     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(sparse_df)\n",
    "head(raw_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleansing & Tidying "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Syntactic errors  \n",
    "**Lexical**: Because the behavioral data is written to lists which are concatenated, there would be a concatenation error if they were of different sizes that would prevent saving the data, so I don't expect there to be any discrepancies between the intended and actual data structure format. However, is possible that the values for two variables could be switched without affecting the size of the list, but I check for this below. \n",
    "\n",
    "**Domain format errors and irregularities**: Because all of the data is written at once, I don't expect there to be formatting inconsistencies, but I check for this type of error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Semantic errors\n",
    "**Integrity constraint violations**: Will check that reaction times are within the minimum (.1 s) and maximum (1 s) set within the experiment. Because the trial should end with a timing message if either the max. or min. reaction time is recorded, if reaction times associated with a non-repeated trial are greater than the maximum or less than the minimum, then a) the reaction time was recorded incorrectly or b) the experiment did not operate as intended. I will check that accuracy, solution, and choice values are all either 0 or 1 and that the high value cue is always either one of the two ASCII values for the colors of the stimuli presented. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "── Attaching packages ─────────────────────────────────────── tidyverse 1.2.1 ──\n",
      "✔ ggplot2 2.2.1     ✔ purrr   0.2.4\n",
      "✔ tibble  1.4.2     ✔ dplyr   0.7.4\n",
      "✔ tidyr   0.7.2     ✔ stringr 1.2.0\n",
      "✔ readr   1.1.1     ✔ forcats 0.2.0\n",
      "── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "✖ dplyr::filter() masks stats::filter()\n",
      "✖ dplyr::lag()    masks stats::lag()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>trial</th><th scope=col>reward</th><th scope=col>total_trial_time</th><th scope=col>accuracy</th><th scope=col>cp_with_slow_fast</th><th scope=col>cumulative_reward</th><th scope=col>high_val_cue</th><th scope=col>iti</th><th scope=col>rt</th><th scope=col>solution</th><th scope=col>choice</th><th scope=col>ID</th><th scope=col>condition</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>1        </td><td>62       </td><td>1.571029 </td><td>1        </td><td>0        </td><td> 62      </td><td>112      </td><td>0.2876267</td><td>0.2779109</td><td>1        </td><td>1        </td><td>758      </td><td>lvhc     </td></tr>\n",
       "\t<tr><td>2        </td><td>55       </td><td>2.015825 </td><td>1        </td><td>0        </td><td>117      </td><td>112      </td><td>0.6198438</td><td>0.4092290</td><td>1        </td><td>1        </td><td>758      </td><td>lvhc     </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllllllll}\n",
       " trial & reward & total\\_trial\\_time & accuracy & cp\\_with\\_slow\\_fast & cumulative\\_reward & high\\_val\\_cue & iti & rt & solution & choice & ID & condition\\\\\n",
       "\\hline\n",
       "\t 1         & 62        & 1.571029  & 1         & 0         &  62       & 112       & 0.2876267 & 0.2779109 & 1         & 1         & 758       & lvhc     \\\\\n",
       "\t 2         & 55        & 2.015825  & 1         & 0         & 117       & 112       & 0.6198438 & 0.4092290 & 1         & 1         & 758       & lvhc     \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "trial | reward | total_trial_time | accuracy | cp_with_slow_fast | cumulative_reward | high_val_cue | iti | rt | solution | choice | ID | condition | \n",
       "|---|---|\n",
       "| 1         | 62        | 1.571029  | 1         | 0         |  62       | 112       | 0.2876267 | 0.2779109 | 1         | 1         | 758       | lvhc      | \n",
       "| 2         | 55        | 2.015825  | 1         | 0         | 117       | 112       | 0.6198438 | 0.4092290 | 1         | 1         | 758       | lvhc      | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  trial reward total_trial_time accuracy cp_with_slow_fast cumulative_reward\n",
       "1 1     62     1.571029         1        0                  62              \n",
       "2 2     55     2.015825         1        0                 117              \n",
       "  high_val_cue iti       rt        solution choice ID  condition\n",
       "1 112          0.2876267 0.2779109 1        1      758 lvhc     \n",
       "2 112          0.6198438 0.4092290 1        1      758 lvhc     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(tidyverse)\n",
    "head(clean_df,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'n_digits for rewards: 2'"
      ],
      "text/latex": [
       "'n\\_digits for rewards: 2'"
      ],
      "text/markdown": [
       "'n_digits for rewards: 2'"
      ],
      "text/plain": [
       "[1] \"n_digits for rewards: 2\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'rewards are integers: TRUE'"
      ],
      "text/latex": [
       "'rewards are integers: TRUE'"
      ],
      "text/markdown": [
       "'rewards are integers: TRUE'"
      ],
      "text/plain": [
       "[1] \"rewards are integers: TRUE\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'total trial time &gt; rt: TRUE'"
      ],
      "text/latex": [
       "'total trial time > rt: TRUE'"
      ],
      "text/markdown": [
       "'total trial time &gt; rt: TRUE'"
      ],
      "text/plain": [
       "[1] \"total trial time > rt: TRUE\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'min and max total trial times:'"
      ],
      "text/latex": [
       "'min and max total trial times:'"
      ],
      "text/markdown": [
       "'min and max total trial times:'"
      ],
      "text/plain": [
       "[1] \"min and max total trial times:\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'1.36802387237549'</li>\n",
       "\t<li>'155.019867897034'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item '1.36802387237549'\n",
       "\\item '155.019867897034'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. '1.36802387237549'\n",
       "2. '155.019867897034'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"1.36802387237549\" \"155.019867897034\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'accuracy is always 0 | 1 : TRUE'"
      ],
      "text/latex": [
       "'accuracy is always 0 \\textbar{} 1 : TRUE'"
      ],
      "text/markdown": [
       "'accuracy is always 0 | 1 : TRUE'"
      ],
      "text/plain": [
       "[1] \"accuracy is always 0 | 1 : TRUE\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'cp_with_slow_fast is always {0,1,-1,-2}: TRUE'"
      ],
      "text/latex": [
       "'cp\\_with\\_slow\\_fast is always \\{0,1,-1,-2\\}: TRUE'"
      ],
      "text/markdown": [
       "'cp_with_slow_fast is always {0,1,-1,-2}: TRUE'"
      ],
      "text/plain": [
       "[1] \"cp_with_slow_fast is always {0,1,-1,-2}: TRUE\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'negative diff is equal to number of total breaks between conditions: TRUE'"
      ],
      "text/latex": [
       "'negative diff is equal to number of total breaks between conditions: TRUE'"
      ],
      "text/markdown": [
       "'negative diff is equal to number of total breaks between conditions: TRUE'"
      ],
      "text/plain": [
       "[1] \"negative diff is equal to number of total breaks between conditions: TRUE\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'indices of negative reward differences: '"
      ],
      "text/latex": [
       "'indices of negative reward differences: '"
      ],
      "text/markdown": [
       "'indices of negative reward differences: '"
      ],
      "text/plain": [
       "[1] \"indices of negative reward differences: \""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>1000</li>\n",
       "\t<li>2000</li>\n",
       "\t<li>3000</li>\n",
       "\t<li>4000</li>\n",
       "\t<li>5000</li>\n",
       "\t<li>6000</li>\n",
       "\t<li>7000</li>\n",
       "\t<li>8000</li>\n",
       "\t<li>9000</li>\n",
       "\t<li>10000</li>\n",
       "\t<li>11000</li>\n",
       "\t<li>12000</li>\n",
       "\t<li>13000</li>\n",
       "\t<li>14000</li>\n",
       "\t<li>15000</li>\n",
       "\t<li>16000</li>\n",
       "\t<li>17000</li>\n",
       "\t<li>18000</li>\n",
       "\t<li>19000</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1000\n",
       "\\item 2000\n",
       "\\item 3000\n",
       "\\item 4000\n",
       "\\item 5000\n",
       "\\item 6000\n",
       "\\item 7000\n",
       "\\item 8000\n",
       "\\item 9000\n",
       "\\item 10000\n",
       "\\item 11000\n",
       "\\item 12000\n",
       "\\item 13000\n",
       "\\item 14000\n",
       "\\item 15000\n",
       "\\item 16000\n",
       "\\item 17000\n",
       "\\item 18000\n",
       "\\item 19000\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1000\n",
       "2. 2000\n",
       "3. 3000\n",
       "4. 4000\n",
       "5. 5000\n",
       "6. 6000\n",
       "7. 7000\n",
       "8. 8000\n",
       "9. 9000\n",
       "10. 10000\n",
       "11. 11000\n",
       "12. 12000\n",
       "13. 13000\n",
       "14. 14000\n",
       "15. 15000\n",
       "16. 16000\n",
       "17. 17000\n",
       "18. 18000\n",
       "19. 19000\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1]  1000  2000  3000  4000  5000  6000  7000  8000  9000 10000 11000 12000\n",
       "[13] 13000 14000 15000 16000 17000 18000 19000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'high val. cue is always purple or orange : TRUE'"
      ],
      "text/latex": [
       "'high val. cue is always purple or orange : TRUE'"
      ],
      "text/markdown": [
       "'high val. cue is always purple or orange : TRUE'"
      ],
      "text/plain": [
       "[1] \"high val. cue is always purple or orange : TRUE\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'obs. min. iti is less than set min. rt: FALSE'"
      ],
      "text/latex": [
       "'obs. min. iti is less than set min. rt: FALSE'"
      ],
      "text/markdown": [
       "'obs. min. iti is less than set min. rt: FALSE'"
      ],
      "text/plain": [
       "[1] \"obs. min. iti is less than set min. rt: FALSE\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'obs. max. iti is greater than set max. rt: FALSE'"
      ],
      "text/latex": [
       "'obs. max. iti is greater than set max. rt: FALSE'"
      ],
      "text/markdown": [
       "'obs. max. iti is greater than set max. rt: FALSE'"
      ],
      "text/plain": [
       "[1] \"obs. max. iti is greater than set max. rt: FALSE\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'obs. min. rt &lt; set min. rt: FALSE'"
      ],
      "text/latex": [
       "'obs. min. rt < set min. rt: FALSE'"
      ],
      "text/markdown": [
       "'obs. min. rt &lt; set min. rt: FALSE'"
      ],
      "text/plain": [
       "[1] \"obs. min. rt < set min. rt: FALSE\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'obs. max. rt &gt; set max. rt: FALSE'"
      ],
      "text/latex": [
       "'obs. max. rt > set max. rt: FALSE'"
      ],
      "text/markdown": [
       "'obs. max. rt &gt; set max. rt: FALSE'"
      ],
      "text/plain": [
       "[1] \"obs. max. rt > set max. rt: FALSE\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'solution is either 0 | 1 : TRUE'"
      ],
      "text/latex": [
       "'solution is either 0 \\textbar{} 1 : TRUE'"
      ],
      "text/markdown": [
       "'solution is either 0 | 1 : TRUE'"
      ],
      "text/plain": [
       "[1] \"solution is either 0 | 1 : TRUE\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'choice is either 0 | 1 : TRUE'"
      ],
      "text/latex": [
       "'choice is either 0 \\textbar{} 1 : TRUE'"
      ],
      "text/markdown": [
       "'choice is either 0 | 1 : TRUE'"
      ],
      "text/plain": [
       "[1] \"choice is either 0 | 1 : TRUE\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"unique subject IDs:\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'758'</li>\n",
       "\t<li>'757'</li>\n",
       "\t<li>'756'</li>\n",
       "\t<li>'759'</li>\n",
       "\t<li>'760'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item '758'\n",
       "\\item '757'\n",
       "\\item '756'\n",
       "\\item '759'\n",
       "\\item '760'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. '758'\n",
       "2. '757'\n",
       "3. '756'\n",
       "4. '759'\n",
       "5. '760'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"758\" \"757\" \"756\" \"759\" \"760\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'obs. number of unique subjects == num. subjects: TRUE'"
      ],
      "text/latex": [
       "'obs. number of unique subjects == num. subjects: TRUE'"
      ],
      "text/markdown": [
       "'obs. number of unique subjects == num. subjects: TRUE'"
      ],
      "text/plain": [
       "[1] \"obs. number of unique subjects == num. subjects: TRUE\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"unique conditions:\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'lvhc'</li>\n",
       "\t<li>'lvlc'</li>\n",
       "\t<li>'hvlc'</li>\n",
       "\t<li>'hvhc'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'lvhc'\n",
       "\\item 'lvlc'\n",
       "\\item 'hvlc'\n",
       "\\item 'hvhc'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'lvhc'\n",
       "2. 'lvlc'\n",
       "3. 'hvlc'\n",
       "4. 'hvhc'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"lvhc\" \"lvlc\" \"hvlc\" \"hvhc\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'obs. number of unique conditions == num. conditions: TRUE'"
      ],
      "text/latex": [
       "'obs. number of unique conditions == num. conditions: TRUE'"
      ],
      "text/markdown": [
       "'obs. number of unique conditions == num. conditions: TRUE'"
      ],
      "text/plain": [
       "[1] \"obs. number of unique conditions == num. conditions: TRUE\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#all rewards should be two digit integers\n",
    "paste0('n_digits for rewards: ', unique(nchar(clean_df$reward)))\n",
    "paste0('rewards are integers: ', sum(clean_df$reward == floor(clean_df$reward)) == length(clean_df$reward))\n",
    "\n",
    "#total trial time is > rt and in appropriate units (ms) \n",
    "paste0('total trial time > rt: ', sum(clean_df$total_trial_time > clean_df$rt) == length(clean_df$total_trial_time))\n",
    "paste0('min and max total trial times:')\n",
    "paste0(range(clean_df$total_trial_time))\n",
    "\n",
    "#accuracy is always 0 or 1 \n",
    "paste0('accuracy is always 0 | 1 : ', sum(clean_df$accuracy == 0 | 1) == length(clean_df$accuracy))\n",
    "\n",
    "#cp_with_slow_fast is always {0,1,-1,-2} \n",
    "slow_flag = -1 \n",
    "fast_flag = -2 \n",
    "paste0('cp_with_slow_fast is always {0,1,-1,-2}: ',  sum(clean_df$cp_with_slow_fast == 0 | 1 | slow_flag | fast_flag) == length(clean_df$cp_with_slow_fast))\n",
    "\n",
    "#if cumulative reward is always increasing within a session, diff should always be positive, except for when condition switches \n",
    "n_conditions = 4 \n",
    "n_subjects = 5\n",
    "#total breaks is n_cond*n_subs - 1 (last condition has no value for diff)\n",
    "n_total_breaks = n_conditions*n_subjects - 1 \n",
    "paste0('negative diff is equal to number of total breaks between conditions: ', sum(sign(diff(clean_df$cumulative_reward)) == -1) == n_total_breaks)\n",
    "#indices of negative diff (when score goes to 0) \n",
    "#should all be intervals of 1000. \n",
    "paste0('indices of negative reward differences: ')\n",
    "which(sign(diff(clean_df$cumulative_reward)) == -1)\n",
    "\n",
    "#high_val_cue is the ASCII value for o (orange) or p (purple) \n",
    "orange = 111\n",
    "purple = 112\n",
    "paste0('high val. cue is always purple or orange : ', sum(clean_df$high_val_cue == orange | purple) == length(clean_df$high_val_cue))\n",
    "\n",
    "#iti is between min. and max. values set in exp. code\n",
    "iti_min = .25\n",
    "iti_max = .75\n",
    "min_rt = .1 \n",
    "max_rt = 1\n",
    "paste0('obs. min. iti is less than set min. rt: ', clean_df$iti %>% min() < min_rt )\n",
    "paste0('obs. max. iti is greater than set max. rt: ', clean_df$iti %>% max() > max_rt )\n",
    "\n",
    "#rts are within specified range \n",
    "paste0('obs. min. rt < set min. rt: ',clean_df$rt %>% min() < min_rt )\n",
    "paste0('obs. max. rt > set max. rt: ',clean_df$rt %>% max() > max_rt)\n",
    "\n",
    "#solutions and choices are either 0/1\n",
    "paste0('solution is either 0 | 1 : ', sum(clean_df$solution == 0 | 1) == length(clean_df$solution))\n",
    "paste0('choice is either 0 | 1 : ', sum(clean_df$choice == 0 | 1) == length(clean_df$choice))\n",
    "\n",
    "#there are 5 unique subjects named properly \n",
    "print('unique subject IDs:')\n",
    "paste0(unique(clean_df$ID))\n",
    "paste0('obs. number of unique subjects == num. subjects: ', length(unique(clean_df$ID)) == n_subjects )\n",
    "\n",
    "#there are 4 unique conditions named properly \n",
    "print('unique conditions:')\n",
    "paste0(unique(clean_df$condition))\n",
    "paste0('obs. number of unique conditions == num. conditions: ', length(unique(clean_df$condition)) == n_conditions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Contradictions**: I will recalculate accuracy from the choice and the solution values to ensure that the accuracy variable does not represent a contradiction. I will ensure that if the experimental constraints on reaction time are not met on a given trial,  the trial is flagged appropriately (-1 or -2 for fast for slow trials), reward is 0, and that the trial is repeated (total n_trials for each participant is 1000 without fast/slow trials). Additionally, I will check that total trial time is always greater than the recorded reaction time, that cumulative reward is always increasing, and that when the cp_with_fast_slow indicator is 1 (indicating a change point), then the ASCII value for the high value cue also changes. \n",
    "<br>\n",
    "**Duplicates**: While some trials should repeat given an out-of-bounds reaction time, I check for repeated recordings of the same trial by finding whether any trial within a subject has repeated values for both reaction time (which has a high degree of precision) and cumulative reward (which should always increase). \n",
    "<br>\n",
    "**Invalid tuples**: I will check that accuracy is moderately variable within a given subject. Given the probabilistic nature of the task, I would not expect a subject to have either perfect accuracy or for that subject to have all incorrect trials. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'accuracy, choice, and solution are not contradictory: TRUE'"
      ],
      "text/latex": [
       "'accuracy, choice, and solution are not contradictory: TRUE'"
      ],
      "text/markdown": [
       "'accuracy, choice, and solution are not contradictory: TRUE'"
      ],
      "text/plain": [
       "[1] \"accuracy, choice, and solution are not contradictory: TRUE\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'sum of flagged fast trials is equal to flagged trials &lt; min_rt : TRUE'"
      ],
      "text/latex": [
       "'sum of flagged fast trials is equal to flagged trials < min\\_rt : TRUE'"
      ],
      "text/markdown": [
       "'sum of flagged fast trials is equal to flagged trials &lt; min_rt : TRUE'"
      ],
      "text/plain": [
       "[1] \"sum of flagged fast trials is equal to flagged trials < min_rt : TRUE\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'sum of flagged slow trials is equal to flagged trials &gt; max_rt : TRUE'"
      ],
      "text/latex": [
       "'sum of flagged slow trials is equal to flagged trials > max\\_rt : TRUE'"
      ],
      "text/markdown": [
       "'sum of flagged slow trials is equal to flagged trials &gt; max_rt : TRUE'"
      ],
      "text/plain": [
       "[1] \"sum of flagged slow trials is equal to flagged trials > max_rt : TRUE\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'sum of trials not flagged as slow == sum of trials not flagged as slow with rt &lt; max_rt : TRUE'"
      ],
      "text/latex": [
       "'sum of trials not flagged as slow == sum of trials not flagged as slow with rt < max\\_rt : TRUE'"
      ],
      "text/markdown": [
       "'sum of trials not flagged as slow == sum of trials not flagged as slow with rt &lt; max_rt : TRUE'"
      ],
      "text/plain": [
       "[1] \"sum of trials not flagged as slow == sum of trials not flagged as slow with rt < max_rt : TRUE\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'sum of trials not flagged as fast == sum of trials not flagged as fast with rt &gt; min_rt : TRUE'"
      ],
      "text/latex": [
       "'sum of trials not flagged as fast == sum of trials not flagged as fast with rt > min\\_rt : TRUE'"
      ],
      "text/markdown": [
       "'sum of trials not flagged as fast == sum of trials not flagged as fast with rt &gt; min_rt : TRUE'"
      ],
      "text/plain": [
       "[1] \"sum of trials not flagged as fast == sum of trials not flagged as fast with rt > min_rt : TRUE\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#recalculating accuracy from choice and solution to check for contradictions \n",
    "recalc_acc = clean_df$solution == clean_df$choice\n",
    "paste0('accuracy, choice, and solution are not contradictory: ',  sum(recalc_acc == clean_df$accuracy) == length(clean_df$accuracy))\n",
    "\n",
    "#check if slow and fast flags are appropriately assigned \n",
    "#the total sum of flags should equal the sum of flags out of rt bounds \n",
    "paste0('sum of flagged fast trials is equal to flagged trials < min_rt : ', sum(raw_df[(raw_df$cp_with_slow_fast == fast_flag), ]$rt < min_rt) == sum(raw_df$cp_with_slow_fast == fast_flag))\n",
    "\n",
    "paste0('sum of flagged slow trials is equal to flagged trials > max_rt : ', sum(raw_df[(raw_df$cp_with_slow_fast == slow_flag), ]$rt > max_rt) == sum(raw_df$cp_with_slow_fast == slow_flag))\n",
    "\n",
    "#make sure that none of the trials escaped flagging if they were out of bounds\n",
    "paste0('sum of trials not flagged as slow == sum of trials not flagged as slow with rt < max_rt : ', sum(raw_df[!(raw_df$cp_with_slow_fast == slow_flag),]$rt < max_rt) == length(raw_df[!(raw_df$cp_with_slow_fast == slow_flag),]$rt))\n",
    "\n",
    "paste0('sum of trials not flagged as fast == sum of trials not flagged as fast with rt > min_rt : ',sum(raw_df[!(raw_df$cp_with_slow_fast == fast_flag),]$rt > min_rt) == length(raw_df[!(raw_df$cp_with_slow_fast == fast_flag),]$rt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>ID</th><th scope=col>condition</th><th scope=col>n</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>756 </td><td>hvhc</td><td>1000</td></tr>\n",
       "\t<tr><td>756 </td><td>hvlc</td><td>1000</td></tr>\n",
       "\t<tr><td>756 </td><td>lvhc</td><td>1000</td></tr>\n",
       "\t<tr><td>756 </td><td>lvlc</td><td>1000</td></tr>\n",
       "\t<tr><td>757 </td><td>hvhc</td><td>1000</td></tr>\n",
       "\t<tr><td>757 </td><td>hvlc</td><td>1000</td></tr>\n",
       "\t<tr><td>757 </td><td>lvhc</td><td>1000</td></tr>\n",
       "\t<tr><td>757 </td><td>lvlc</td><td>1000</td></tr>\n",
       "\t<tr><td>758 </td><td>hvhc</td><td>1000</td></tr>\n",
       "\t<tr><td>758 </td><td>hvlc</td><td>1000</td></tr>\n",
       "\t<tr><td>758 </td><td>lvhc</td><td>1000</td></tr>\n",
       "\t<tr><td>758 </td><td>lvlc</td><td>1000</td></tr>\n",
       "\t<tr><td>759 </td><td>hvhc</td><td>1000</td></tr>\n",
       "\t<tr><td>759 </td><td>hvlc</td><td>1000</td></tr>\n",
       "\t<tr><td>759 </td><td>lvhc</td><td>1000</td></tr>\n",
       "\t<tr><td>759 </td><td>lvlc</td><td>1000</td></tr>\n",
       "\t<tr><td>760 </td><td>hvhc</td><td>1000</td></tr>\n",
       "\t<tr><td>760 </td><td>hvlc</td><td>1000</td></tr>\n",
       "\t<tr><td>760 </td><td>lvhc</td><td>1000</td></tr>\n",
       "\t<tr><td>760 </td><td>lvlc</td><td>1000</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       " ID & condition & n\\\\\n",
       "\\hline\n",
       "\t 756  & hvhc & 1000\\\\\n",
       "\t 756  & hvlc & 1000\\\\\n",
       "\t 756  & lvhc & 1000\\\\\n",
       "\t 756  & lvlc & 1000\\\\\n",
       "\t 757  & hvhc & 1000\\\\\n",
       "\t 757  & hvlc & 1000\\\\\n",
       "\t 757  & lvhc & 1000\\\\\n",
       "\t 757  & lvlc & 1000\\\\\n",
       "\t 758  & hvhc & 1000\\\\\n",
       "\t 758  & hvlc & 1000\\\\\n",
       "\t 758  & lvhc & 1000\\\\\n",
       "\t 758  & lvlc & 1000\\\\\n",
       "\t 759  & hvhc & 1000\\\\\n",
       "\t 759  & hvlc & 1000\\\\\n",
       "\t 759  & lvhc & 1000\\\\\n",
       "\t 759  & lvlc & 1000\\\\\n",
       "\t 760  & hvhc & 1000\\\\\n",
       "\t 760  & hvlc & 1000\\\\\n",
       "\t 760  & lvhc & 1000\\\\\n",
       "\t 760  & lvlc & 1000\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "ID | condition | n | \n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 756  | hvhc | 1000 | \n",
       "| 756  | hvlc | 1000 | \n",
       "| 756  | lvhc | 1000 | \n",
       "| 756  | lvlc | 1000 | \n",
       "| 757  | hvhc | 1000 | \n",
       "| 757  | hvlc | 1000 | \n",
       "| 757  | lvhc | 1000 | \n",
       "| 757  | lvlc | 1000 | \n",
       "| 758  | hvhc | 1000 | \n",
       "| 758  | hvlc | 1000 | \n",
       "| 758  | lvhc | 1000 | \n",
       "| 758  | lvlc | 1000 | \n",
       "| 759  | hvhc | 1000 | \n",
       "| 759  | hvlc | 1000 | \n",
       "| 759  | lvhc | 1000 | \n",
       "| 759  | lvlc | 1000 | \n",
       "| 760  | hvhc | 1000 | \n",
       "| 760  | hvlc | 1000 | \n",
       "| 760  | lvhc | 1000 | \n",
       "| 760  | lvlc | 1000 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "   ID  condition n   \n",
       "1  756 hvhc      1000\n",
       "2  756 hvlc      1000\n",
       "3  756 lvhc      1000\n",
       "4  756 lvlc      1000\n",
       "5  757 hvhc      1000\n",
       "6  757 hvlc      1000\n",
       "7  757 lvhc      1000\n",
       "8  757 lvlc      1000\n",
       "9  758 hvhc      1000\n",
       "10 758 hvlc      1000\n",
       "11 758 lvhc      1000\n",
       "12 758 lvlc      1000\n",
       "13 759 hvhc      1000\n",
       "14 759 hvlc      1000\n",
       "15 759 lvhc      1000\n",
       "16 759 lvlc      1000\n",
       "17 760 hvhc      1000\n",
       "18 760 hvlc      1000\n",
       "19 760 lvhc      1000\n",
       "20 760 lvlc      1000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'all slow trials have reward of 0: TRUE'"
      ],
      "text/latex": [
       "'all slow trials have reward of 0: TRUE'"
      ],
      "text/markdown": [
       "'all slow trials have reward of 0: TRUE'"
      ],
      "text/plain": [
       "[1] \"all slow trials have reward of 0: TRUE\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'all fast trials have reward of 0: TRUE'"
      ],
      "text/latex": [
       "'all fast trials have reward of 0: TRUE'"
      ],
      "text/markdown": [
       "'all fast trials have reward of 0: TRUE'"
      ],
      "text/plain": [
       "[1] \"all fast trials have reward of 0: TRUE\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#make sure that each subject and condition combination has exactly 1000 trials after cleaning \n",
    "clean_df %>% \n",
    "group_by(ID, condition) %>%\n",
    "count()\n",
    "\n",
    "#out-of-bounds trials should have reward value of 0\n",
    "fast_idx = which(raw_df$cp_with_slow_fast == fast_flag)\n",
    "slow_idx = which(raw_df$cp_with_slow_fast == slow_flag)\n",
    "\n",
    "paste0('all slow trials have reward of 0: ', sum(raw_df$reward[slow_idx] == 0) == length(raw_df$reward[slow_idx]))\n",
    "\n",
    "paste0('all fast trials have reward of 0: ', sum(raw_df$reward[fast_idx] == 0) == length(raw_df$reward[fast_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'duplicated trials: 0'"
      ],
      "text/latex": [
       "'duplicated trials: 0'"
      ],
      "text/markdown": [
       "'duplicated trials: 0'"
      ],
      "text/plain": [
       "[1] \"duplicated trials: 0\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#check for duplicated trials\n",
    "paste0('duplicated trials: ', sum(duplicated(raw_df[,c(\"rt\", \"cumulative_reward\")])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'rewarding cue flipped at changepoint: TRUE'"
      ],
      "text/latex": [
       "'rewarding cue flipped at changepoint: TRUE'"
      ],
      "text/markdown": [
       "'rewarding cue flipped at changepoint: TRUE'"
      ],
      "text/plain": [
       "[1] \"rewarding cue flipped at changepoint: TRUE\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#make sure that high value cue is flipped given changepoint\n",
    "cp_idx = which(raw_df$cp_with_slow_fast == 1)\n",
    "na_trials = sum(is.na(raw_df$high_val_cue[cp_idx]))\n",
    "#if flipped, sum should equal the number of changepoints\n",
    "paste0('rewarding cue flipped at changepoint: ', (sum(raw_df$high_val_cue[cp_idx] != raw_df$high_val_cue[cp_idx-1], na.rm=TRUE) + na_trials) == length(cp_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>condition</th><th scope=col>ID</th><th scope=col>mean_acc</th><th scope=col>std_acc</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>hvhc     </td><td>756      </td><td>0.941    </td><td>0.2357426</td></tr>\n",
       "\t<tr><td>hvhc     </td><td>757      </td><td>0.774    </td><td>0.4184484</td></tr>\n",
       "\t<tr><td>hvhc     </td><td>758      </td><td>0.911    </td><td>0.2848862</td></tr>\n",
       "\t<tr><td>hvhc     </td><td>759      </td><td>0.941    </td><td>0.2357426</td></tr>\n",
       "\t<tr><td>hvhc     </td><td>760      </td><td>0.909    </td><td>0.2877530</td></tr>\n",
       "\t<tr><td>hvlc     </td><td>756      </td><td>0.941    </td><td>0.2357426</td></tr>\n",
       "\t<tr><td>hvlc     </td><td>757      </td><td>0.934    </td><td>0.2484063</td></tr>\n",
       "\t<tr><td>hvlc     </td><td>758      </td><td>0.950    </td><td>0.2180540</td></tr>\n",
       "\t<tr><td>hvlc     </td><td>759      </td><td>0.925    </td><td>0.2635231</td></tr>\n",
       "\t<tr><td>hvlc     </td><td>760      </td><td>0.920    </td><td>0.2714289</td></tr>\n",
       "\t<tr><td>lvhc     </td><td>756      </td><td>0.943    </td><td>0.2319586</td></tr>\n",
       "\t<tr><td>lvhc     </td><td>757      </td><td>0.973    </td><td>0.1621644</td></tr>\n",
       "\t<tr><td>lvhc     </td><td>758      </td><td>0.954    </td><td>0.2095899</td></tr>\n",
       "\t<tr><td>lvhc     </td><td>759      </td><td>0.926    </td><td>0.2619019</td></tr>\n",
       "\t<tr><td>lvhc     </td><td>760      </td><td>0.964    </td><td>0.1863833</td></tr>\n",
       "\t<tr><td>lvlc     </td><td>756      </td><td>0.969    </td><td>0.1734044</td></tr>\n",
       "\t<tr><td>lvlc     </td><td>757      </td><td>0.977    </td><td>0.1499783</td></tr>\n",
       "\t<tr><td>lvlc     </td><td>758      </td><td>0.971    </td><td>0.1678904</td></tr>\n",
       "\t<tr><td>lvlc     </td><td>759      </td><td>0.970    </td><td>0.1706726</td></tr>\n",
       "\t<tr><td>lvlc     </td><td>760      </td><td>0.974    </td><td>0.1592148</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       " condition & ID & mean\\_acc & std\\_acc\\\\\n",
       "\\hline\n",
       "\t hvhc      & 756       & 0.941     & 0.2357426\\\\\n",
       "\t hvhc      & 757       & 0.774     & 0.4184484\\\\\n",
       "\t hvhc      & 758       & 0.911     & 0.2848862\\\\\n",
       "\t hvhc      & 759       & 0.941     & 0.2357426\\\\\n",
       "\t hvhc      & 760       & 0.909     & 0.2877530\\\\\n",
       "\t hvlc      & 756       & 0.941     & 0.2357426\\\\\n",
       "\t hvlc      & 757       & 0.934     & 0.2484063\\\\\n",
       "\t hvlc      & 758       & 0.950     & 0.2180540\\\\\n",
       "\t hvlc      & 759       & 0.925     & 0.2635231\\\\\n",
       "\t hvlc      & 760       & 0.920     & 0.2714289\\\\\n",
       "\t lvhc      & 756       & 0.943     & 0.2319586\\\\\n",
       "\t lvhc      & 757       & 0.973     & 0.1621644\\\\\n",
       "\t lvhc      & 758       & 0.954     & 0.2095899\\\\\n",
       "\t lvhc      & 759       & 0.926     & 0.2619019\\\\\n",
       "\t lvhc      & 760       & 0.964     & 0.1863833\\\\\n",
       "\t lvlc      & 756       & 0.969     & 0.1734044\\\\\n",
       "\t lvlc      & 757       & 0.977     & 0.1499783\\\\\n",
       "\t lvlc      & 758       & 0.971     & 0.1678904\\\\\n",
       "\t lvlc      & 759       & 0.970     & 0.1706726\\\\\n",
       "\t lvlc      & 760       & 0.974     & 0.1592148\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "condition | ID | mean_acc | std_acc | \n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| hvhc      | 756       | 0.941     | 0.2357426 | \n",
       "| hvhc      | 757       | 0.774     | 0.4184484 | \n",
       "| hvhc      | 758       | 0.911     | 0.2848862 | \n",
       "| hvhc      | 759       | 0.941     | 0.2357426 | \n",
       "| hvhc      | 760       | 0.909     | 0.2877530 | \n",
       "| hvlc      | 756       | 0.941     | 0.2357426 | \n",
       "| hvlc      | 757       | 0.934     | 0.2484063 | \n",
       "| hvlc      | 758       | 0.950     | 0.2180540 | \n",
       "| hvlc      | 759       | 0.925     | 0.2635231 | \n",
       "| hvlc      | 760       | 0.920     | 0.2714289 | \n",
       "| lvhc      | 756       | 0.943     | 0.2319586 | \n",
       "| lvhc      | 757       | 0.973     | 0.1621644 | \n",
       "| lvhc      | 758       | 0.954     | 0.2095899 | \n",
       "| lvhc      | 759       | 0.926     | 0.2619019 | \n",
       "| lvhc      | 760       | 0.964     | 0.1863833 | \n",
       "| lvlc      | 756       | 0.969     | 0.1734044 | \n",
       "| lvlc      | 757       | 0.977     | 0.1499783 | \n",
       "| lvlc      | 758       | 0.971     | 0.1678904 | \n",
       "| lvlc      | 759       | 0.970     | 0.1706726 | \n",
       "| lvlc      | 760       | 0.974     | 0.1592148 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "   condition ID  mean_acc std_acc  \n",
       "1  hvhc      756 0.941    0.2357426\n",
       "2  hvhc      757 0.774    0.4184484\n",
       "3  hvhc      758 0.911    0.2848862\n",
       "4  hvhc      759 0.941    0.2357426\n",
       "5  hvhc      760 0.909    0.2877530\n",
       "6  hvlc      756 0.941    0.2357426\n",
       "7  hvlc      757 0.934    0.2484063\n",
       "8  hvlc      758 0.950    0.2180540\n",
       "9  hvlc      759 0.925    0.2635231\n",
       "10 hvlc      760 0.920    0.2714289\n",
       "11 lvhc      756 0.943    0.2319586\n",
       "12 lvhc      757 0.973    0.1621644\n",
       "13 lvhc      758 0.954    0.2095899\n",
       "14 lvhc      759 0.926    0.2619019\n",
       "15 lvhc      760 0.964    0.1863833\n",
       "16 lvlc      756 0.969    0.1734044\n",
       "17 lvlc      757 0.977    0.1499783\n",
       "18 lvlc      758 0.971    0.1678904\n",
       "19 lvlc      759 0.970    0.1706726\n",
       "20 lvlc      760 0.974    0.1592148"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#accuracy should be moderately variable \n",
    "clean_df %>% \n",
    "group_by(condition, ID) %>% \n",
    "summarise (mean_acc = mean(accuracy), std_acc = sd(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coverage \n",
    "**Missing values & missing tuples**: Missing values within a variable should not be a problem because the data would not save due to a concatenation error. Missing data vectors also should not be a problem because of the automated data collection, but I check that the data from each subject matches the expected size (number of trials by number of variables) below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. TRUE\n",
       "2. TRUE\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] TRUE TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#check that dimensions of cleaned dataframe match n (n_total_trials) x p (n_variables)\n",
    "n_clean_trials_per_s = 1000 \n",
    "n_total_trials = n_clean_trials_per_s * n_conditions * n_subjects\n",
    "n_variables = 13 \n",
    "dim(clean_df) == c(n_total_trials, n_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Analysis [To be completed]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Conclusions [To be completed]**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
